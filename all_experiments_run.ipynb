{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"4chopBnZPc4z","executionInfo":{"status":"ok","timestamp":1754071756132,"user_tz":-180,"elapsed":8,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["########---IMPORTS---#################"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ARujIuchH3cj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754071771052,"user_tz":-180,"elapsed":14919,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}},"outputId":"27ad221b-183f-400c-e875-2135c211d4c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"id":"PUcdZ_3ZR5zy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754071778259,"user_tz":-180,"elapsed":7209,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}},"outputId":"779dead7-c6ac-43d8-e85d-1e5491082ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikeras\n","  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.10.0)\n","Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.17.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.5.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.14.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n","Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.13.0\n"]}],"source":["!pip install scikeras"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2SMHEe4oO90Y","executionInfo":{"status":"ok","timestamp":1754071785611,"user_tz":-180,"elapsed":7352,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import make_scorer, accuracy_score, f1_score, mean_absolute_percentage_error\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from scipy.stats import pearsonr\n","from sklearn.dummy import DummyRegressor, DummyClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from scikeras.wrappers import KerasClassifier, KerasRegressor\n","import pandas as pd\n","import glob\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense, LSTM\n","from joblib import Parallel, delayed"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nVcNLVZZRhb1","executionInfo":{"status":"ok","timestamp":1754071785614,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["#########---PATHS---#############\n","random = '/content/drive/MyDrive/data_driven_shm/random_data'\n","balanced = '/content/drive/MyDrive/data_driven_shm/Balanced_data'\n","test = '/content/drive/MyDrive/data_driven_shm/test_classification'\n","\n","\n","#########---INPUTS---#############\n","\n","n_points_list = [375, 460, 750]\n","transformation_list = ['none', 'fourier']\n","noise_levels = [2, 5, 10]\n","damage_percentage = [0.3 , 0.5 ,1]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"o8F-zq7t1ril","executionInfo":{"status":"ok","timestamp":1754071785660,"user_tz":-180,"elapsed":47,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["####---FOURIER---######\n","def fourier(sample_sensor):\n","    '''\n","    The input is a signal\n","    The output is the amplitude and the frequency of the fft of the signal\n","    '''\n","    import numpy as np\n","    fs = 1/1000\n","    fourier = np.fft.fft(sample_sensor)\n","    freqs = np.fft.fftfreq(sample_sensor.size,d=fs)\n","    power_spectrum = np.abs(fourier)\n","    power_spectrum = np.log(power_spectrum)\n","\n","    return power_spectrum,freqs"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tozbFsvpO_19","executionInfo":{"status":"ok","timestamp":1754071785736,"user_tz":-180,"elapsed":76,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["def random_forest_reg():\n","    from sklearn.ensemble import RandomForestRegressor\n","    rf = RandomForestRegressor()\n","    return rf\n","\n","\n","\n","def linear_regression():\n","\n","    from sklearn.linear_model import LinearRegression\n","    lr = LinearRegression()\n","\n","    return lr\n","\n","\n","\n","def svc():\n","    from sklearn.svm import SVC\n","    svm =SVC(C=100,gamma=0.001,kernel='rbf')\n","\n","    return svm\n","\n","def random_forest_clf():\n","    from sklearn.ensemble import RandomForestClassifier\n","    rf = RandomForestClassifier(n_estimators=500,criterion='entropy')\n","\n","    return rf\n","\n","\n","\n","##################----------- NNs-----------##################\n","from scikeras.wrappers import KerasClassifier, KerasRegressor\n","\n","\n","\n","def keras_mlp_regressor(input_shape):\n","    '''\n","    paizei kala mono gia scaled !!!!!!!!!!!!!!!!!!!!!\n","\n","    '''\n","    import tensorflow as tf\n","    from tensorflow import keras\n","    from keras.models import Sequential\n","    from keras.layers import Flatten,Dense\n","\n","    mlp = Sequential()\n","    mlp.add(Dense(256, activation='sigmoid', input_shape=input_shape))\n","    # Dense layer 2 (128 neurons)\n","    mlp.add(Dense(128, activation='sigmoid'))\n","    mlp.add(Dense(64, activation='sigmoid'))\n","    #mlp.add(Dense(32, activation='sigmoid'))\n","    # Output layer (10 classes)\n","    mlp.add(Dense(10, activation='sigmoid'))\n","    mlp.add(Dense(1, activation='linear'))\n","\n","    mlp.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n","\n","    return mlp\n","\n","def keras_mlp_classifier(input_shape):\n","    import tensorflow as tf\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.layers import Dense\n","\n","    model = Sequential()\n","    model.add(Dense(256, activation='sigmoid', input_shape=input_shape))\n","    model.add(Dense(128, activation='sigmoid'))\n","    model.add(Dense(64, activation='sigmoid'))\n","    model.add(Dense(4))  # No activation for logits\n","    model.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","\n","    return model\n","\n","\n","def keras_cnn_regressor(input_shape):\n","    import tensorflow as tf\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense\n","\n","    model = Sequential([\n","        Conv1D(16, 3, padding='same', activation='relu', input_shape=input_shape),\n","        MaxPooling1D(),\n","        Conv1D(32, 3, padding='same', activation='relu'),\n","        MaxPooling1D(),\n","        Conv1D(64, 3, padding='same', activation='relu'),\n","        MaxPooling1D(),\n","        Flatten(),\n","        Dropout(0.2),\n","        Dense(1)\n","    ])\n","    model.compile(optimizer='adam', loss=\"mean_absolute_error\")\n","\n","    return model\n","\n","\n","def keras_cnn_classifier(input_shape):\n","    import tensorflow as tf\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout, Dense\n","\n","    model = Sequential([\n","        Conv1D(16, 3, padding='same', activation='relu', input_shape=input_shape),\n","        MaxPooling1D(),\n","        Conv1D(32, 3, padding='same', activation='relu'),\n","        MaxPooling1D(),\n","        Conv1D(64, 3, padding='same', activation='relu'),\n","        MaxPooling1D(),\n","        Flatten(),\n","        Dropout(0.2),\n","        Dense(4)\n","    ])\n","    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","\n","    return model\n","\n","\n","def keras_lstm_regressor(input_shape):\n","    import tensorflow as tf\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.layers import Dropout, Dense, LSTM\n","    model = Sequential([\n","        LSTM(100, return_sequences=True, input_shape=input_shape),\n","        Dropout(0.3),\n","        LSTM(50),\n","        Dropout(0.3),\n","        Dense(50, activation=\"relu\"),\n","        Dense(1)\n","    ])\n","    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n","\n","    return model\n","\n","\n","def keras_lstm_classifier(input_shape):\n","    import tensorflow as tf\n","    from tensorflow.keras.models import Sequential\n","    from tensorflow.keras.layers import Dropout, Dense, LSTM\n","    model = Sequential([\n","        LSTM(100, return_sequences=True, input_shape=input_shape),\n","        Dropout(0.3),\n","        LSTM(50),\n","        Dropout(0.3),\n","        Dense(50, activation=\"relu\"),\n","        Dense(4, activation=\"softmax\")\n","    ])\n","    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PVHwOucVPjgn","executionInfo":{"status":"ok","timestamp":1754071785765,"user_tz":-180,"elapsed":27,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["########---- X AND Y SET---########\n","########---- X AND Y SET---########\n","\n","\n","def X_set(path, transformation, n_points, noise_percent=None):\n","    '''\n","    transformations: 'none', 'fourier'\n","    - For 'none': returns truncated raw time-series (first n_points).\n","    - For 'fourier': returns truncated FFT amplitude and frequency vectors (first n_points).\n","    - Noise (if noise_percent is provided) is added before transformation.\n","    '''\n","    import os\n","    import glob\n","    import numpy as np\n","    import pandas as pd\n","\n","    sensor_data_list = []\n","    name_list = []\n","\n","    for filename in sorted(glob.glob(os.path.join(path, \"data*\"))):\n","        filename = filename.removesuffix('.csv')\n","        name_list.append(filename)\n","\n","    sensor_data = pd.DataFrame({'name': name_list})\n","    sensor_data['sensor_index_number'] = [int(i.split('_')[-1]) for i in sensor_data['name']]\n","    sensor_data = sensor_data.sort_values(by='sensor_index_number')\n","    new_names = [name + '.csv' for name in sensor_data['name']]\n","\n","    for filename in new_names:\n","        df = pd.read_csv(filename, sep=' |,', engine='python').dropna()\n","        sensor_data_list.append(df)\n","\n","    freq_list = []\n","    power_spectrum_list = []\n","    sensor_names = ['s2', 's3', 's4']\n","\n","    for sensor in sensor_names:\n","        for i in range(len(sensor_data_list)):\n","            sample_sensor = sensor_data_list[i][sensor].values[:n_points]\n","\n","            if noise_percent is not None:\n","                sample_sensor = add_noiz(sample_sensor.reshape(1, -1), noise_percent).flatten()\n","\n","            if transformation == 'fourier':\n","                amp, freq = fourier(sample_sensor)\n","                amp = amp[:n_points]\n","                power_spectrum = amp\n","\n","                if sensor == 's2':  # Only append freq once per file\n","                    freq = freq[:n_points]\n","                    freq_list.append(freq)\n","\n","            elif transformation == 'none':\n","                power_spectrum = sample_sensor\n","\n","            power_spectrum_list.append(power_spectrum)\n","\n","    num_samples = len(power_spectrum_list) // 3\n","    sensor2_vector = power_spectrum_list[0:num_samples]\n","    sensor3_vector = power_spectrum_list[num_samples:2 * num_samples]\n","    sensor4_vector = power_spectrum_list[2 * num_samples:3 * num_samples]\n","\n","    X = np.concatenate((sensor2_vector, sensor3_vector, sensor4_vector), axis=1)\n","\n","    return X, sensor2_vector, sensor3_vector, sensor4_vector, freq_list\n","\n","\n","\n","def y_set(path):\n","\n","    '''\n","    select column ['dmg'] which is the damage percentage for regression or ['defect'] which is the defect for classification\n","\n","    '''\n","    import numpy as np\n","    import pandas as pd\n","    import os\n","    import glob\n","\n","    dmg_list = []\n","    name_list = []\n","    case_list = []\n","    defect_list =[]\n","    for filename in glob.glob(os.path.join(path , \"meta*\")):\n","        df = pd.read_csv(filename,sep=' |,', engine='python')\n","        dmg_perc = df['Damage_percentage']\n","        case = df['caseStudey'][0]\n","        dmg_perc = dmg_perc[0]\n","        dmg_list.append(dmg_perc)\n","        filename = filename.removesuffix('.csv')\n","\n","        df_defect = df['DamageLayer1'][0] + df['DamageLayer3'][0] + df['DamageLayer5'][0]\n","        dm_defect = df['DamageLayer1'][1] + df['DamageLayer3'][1] + df['DamageLayer5'][1]\n","        dd_defect = df['DamageLayer2'][0] + df['DamageLayer4'][0]\n","\n","        if df_defect ==0 and dm_defect ==0 and dd_defect ==0:\n","            defect_list.append('clean')\n","        elif df_defect !=0 and dm_defect !=0 and dd_defect !=0:\n","            defect_list.append('all defect modes')\n","        elif df_defect !=0 and dm_defect ==0 and dd_defect ==0:\n","            defect_list.append('df')\n","        elif df_defect ==0 and dm_defect !=0 and dd_defect ==0:\n","            defect_list.append('dm')\n","        elif df_defect ==0 and dm_defect ==0 and dd_defect !=0:\n","            defect_list.append('dd')\n","        else:\n","            defect_list.append('all defect modes')\n","\n","        name_list.append(filename)\n","        case_list.append(case)\n","\n","    dmg_data = pd.DataFrame({'dmg':dmg_list,'damage_file_name':name_list,'caseStudey':case_list,'defect':defect_list})\n","    dmg_data['dmg_index_number'] = [int(i.split('_')[-1]) for i in dmg_data['damage_file_name']]\n","    dmg_data = dmg_data.sort_values(by=['dmg_index_number'])\n","    return dmg_data"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"H6MLdO9C8hPM","executionInfo":{"status":"ok","timestamp":1754071785815,"user_tz":-180,"elapsed":37,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["#### NOISE#####\n","\n","\n","def add_noiz(X, noise_percent):\n","    import numpy as np\n","    '''\n","    Adds Gaussian noise to X.\n","    Handles both 2D numpy arrays and lists of 1D arrays (e.g. from X_set with 'fourier' or 'none').\n","    '''\n","    if isinstance(X, np.ndarray):\n","        # Case 1: 2D numpy array (samples x features)\n","        std_dev = np.std(X, axis=0)\n","        noise = np.random.randn(*X.shape) * (noise_percent / 100.0) * std_dev\n","        return X + noise\n","\n","    elif isinstance(X, list) or isinstance(X, tuple):\n","        X_noisy = []\n","        for sample in X:\n","            sample = np.asarray(sample)\n","            std_dev = np.std(sample)\n","            noise = np.random.randn(*sample.shape) * (noise_percent / 100.0) * std_dev\n","            noisy_sample = sample + noise\n","            X_noisy.append(noisy_sample)\n","        return X_noisy"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bJ_HPIpvP6Ho","executionInfo":{"status":"ok","timestamp":1754071785848,"user_tz":-180,"elapsed":34,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["######---PEARSON CORRELATION---##########\n","\n","def p_val(y_true, y_pred):\n","    return pearsonr(y_true, y_pred)[1]"]},{"cell_type":"code","source":["#### --- DATA MIXER---####\n","\n","def data_mixer(X_1,y_1,X_2,y_2,first_percentage,second_percentage):\n","    from sklearn.model_selection import train_test_split\n","    import numpy as np\n","    if first_percentage == 1:\n","        X_1_half = X_1\n","        y_1_half = y_1\n","    else:\n","        X_1_half, X_drop, y_1_half, y_drop = train_test_split(X_1, y_1, test_size=1-first_percentage,shuffle=True)\n","\n","    if second_percentage ==1:\n","        X_2_half = X_2\n","        y_2_half = y_2\n","    else:\n","        X_2_half, X_drop, y_2_half, y_drop = train_test_split(X_2, y_2, test_size=1-second_percentage,shuffle=True)\n","\n","    X_train = np.concatenate((X_1_half,X_2_half),axis=0)\n","    y_train = np.concatenate((y_1_half,y_2_half),axis=0)\n","    return X_train,y_train\n"],"metadata":{"id":"A6HsKvBeufYV","executionInfo":{"status":"ok","timestamp":1754071785849,"user_tz":-180,"elapsed":1,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"id":"dTQ4KlNfP943","executionInfo":{"status":"ok","timestamp":1754071785893,"user_tz":-180,"elapsed":43,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["import tensorflow as tf\n","# --- Regression experiment ---\n","def run_regression_fold(model_fn, X, X_dl, y, train_idx, test_idx, is_dl):\n","    model = model_fn()\n","    X_train = X_dl[train_idx] if is_dl else X[train_idx]\n","    X_test = X_dl[test_idx] if is_dl else X[test_idx]\n","    model.fit(X_train, y[train_idx])\n","    preds = model.predict(X_test)\n","    mape = mean_absolute_percentage_error(y[test_idx], preds)\n","    pval = p_val(y[test_idx], preds)\n","    return mape, pval, preds, y[test_idx]\n","\n","\n","def regression_experiment_run():\n","    for n_points in n_points_list:\n","        all_results = []\n","\n","        for transformation in transformation_list:\n","            y_random = y_set(random)['dmg']\n","            y_data = y_set(balanced)['dmg']\n","\n","            for noise_percent in noise_levels:\n","                X_random = X_set(random, transformation, n_points, noise_percent=noise_percent)[0]\n","                X_data = X_set(balanced, transformation, n_points, noise_percent=noise_percent)[0]\n","\n","                for perc in damage_percentage:\n","                    X_mixed, y_mixed = data_mixer(X_data, y_data, X_random, y_random, perc, perc)\n","\n","                    scaler = StandardScaler()\n","                    X= scaler.fit_transform(X_mixed)\n","                    y = y_mixed\n","\n","                    X_dl = np.expand_dims(X, axis=-1)\n","                    input_shape = X.shape[1]\n","\n","                    model_fns = {\n","                        'LinearRegression': lambda: linear_regression()\n","                        ,\n","                        'RandomForest': lambda: random_forest_reg(),\n","                        'MLP': lambda: KerasRegressor(model=keras_mlp_regressor, model__input_shape=(input_shape,), epochs=150, batch_size=64, verbose=0),\n","                        'CNN': lambda: KerasRegressor(model=keras_cnn_regressor, model__input_shape=(input_shape, 1), epochs=150, batch_size=64, verbose=0),\n","                        'LSTM': lambda: KerasRegressor(model=keras_lstm_regressor, model__input_shape=(input_shape, 1), epochs=150, batch_size=64, verbose=0),\n","                    }\n","\n","                    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n","\n","                    for name, model_fn in model_fns.items():\n","                        is_dl = name in ['MLP', 'CNN', 'LSTM']\n","                        tasks = [\n","                            delayed(run_regression_fold)(model_fn, X, X_dl, y, train_idx, test_idx, is_dl)\n","                            for train_idx, test_idx in cv.split(X)\n","                        ]\n","                        results_fold = Parallel(n_jobs=2, backend='loky')(tasks)\n","                        mape_scores, pval_scores, preds_list, y_true_list = zip(*results_fold)\n","\n","                        all_results.append({\n","                            'n_points': n_points,\n","                            'transformation': transformation,\n","                            'noise_percent': noise_percent,\n","                            'data_percentage': perc,\n","                            'model': name,\n","                            'mean_mape': np.mean(mape_scores),\n","                            'std_mape': np.std(mape_scores),\n","                            'pval': np.mean(pval_scores),\n","                            'last_fold_preds': preds_list[-1].tolist(),\n","                            'last_fold_true': y_true_list[-1].tolist()\n","                        })\n","\n","            df = pd.DataFrame(all_results)\n","            df.to_csv(f'regression_results_n{n_points}.csv', index=False)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"collapsed":true,"id":"ogvkiDm0QKED","executionInfo":{"status":"ok","timestamp":1754071785899,"user_tz":-180,"elapsed":11,"user":{"displayName":"Dimitrios Iason Papadopoulos","userId":"01616260529150161868"}}},"outputs":[],"source":["# --- Classification experiment ---\n","def run_classification_fold(model_fn, X, X_dl, y, train_idx, test_idx, is_dl):\n","    model = model_fn()\n","    X_train = X_dl[train_idx] if is_dl else X[train_idx]\n","    X_test = X_dl[test_idx] if is_dl else X[test_idx]\n","    model.fit(X_train, y[train_idx])\n","    preds = model.predict(X_test)\n","    acc = accuracy_score(y[test_idx], preds)\n","    f1 = f1_score(y[test_idx], preds, average='macro')\n","    return acc, f1, preds, y[test_idx]\n","\n","\n","\n","def classification_experiment_run():\n","    for n_points in n_points_list:\n","        all_results = []\n","\n","        for transformation in transformation_list:\n","            y_data = y_set(balanced)['defect']\n","            y_test = y_set(test)['defect']\n","\n","            label_map = {label: i for i, label in enumerate(set(y_data) | set(y_test))}\n","            y_data = np.array([label_map[label] for label in y_data])\n","            y_test = np.array([label_map[label] for label in y_test])\n","\n","            for noise_percent in noise_levels:\n","                X_data = X_set(balanced, transformation, n_points, noise_percent=noise_percent)[0]\n","                X_test = X_set(test, transformation, n_points, noise_percent=noise_percent)[0]\n","                for perc in damage_percentage:\n","                    X_mixed, y_mixed = data_mixer(X_data, y_data, X_test, y_test, perc, perc)\n","\n","                    scaler = StandardScaler()\n","                    X = scaler.fit_transform(X_mixed)\n","                    y = y_mixed\n","                    X_dl = np.expand_dims(X, axis=-1)\n","                    input_shape = X.shape[1]\n","\n","                    model_fns = {\n","                        'SVC': lambda: svc()\n","                       ,\n","                        'RandomForest': lambda: random_forest_clf(),\n","                        'MLP': lambda: KerasClassifier(model=keras_mlp_classifier, model__input_shape=(input_shape,), epochs=150, batch_size=64, verbose=0),\n","                        'CNN': lambda: KerasClassifier(model=keras_cnn_classifier, model__input_shape=(input_shape, 1), epochs=150, batch_size=64, verbose=0),\n","                        'LSTM': lambda: KerasClassifier(model=keras_lstm_classifier, model__input_shape=(input_shape, 1), epochs=150, batch_size=64, verbose=0),\n","                    }\n","\n","                    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n","\n","                    for name, model_fn in model_fns.items():\n","                        is_dl = name in ['MLP', 'CNN', 'LSTM']\n","                        tasks = [\n","                            delayed(run_classification_fold)(model_fn, X, X_dl, y, train_idx, test_idx, is_dl)\n","                            for train_idx, test_idx in cv.split(X)\n","                        ]\n","                        results_fold = Parallel(n_jobs=2, backend='loky')(tasks)\n","                        acc_scores, f1_scores, preds_list, y_true_list = zip(*results_fold)\n","\n","                        all_results.append({\n","                            'n_points': n_points,\n","                            'transformation': transformation,\n","                            'noise_percent': noise_percent,\n","                            'data_percentage': perc,\n","                            'model': name,\n","                            'mean_acc': np.mean(acc_scores),\n","                            'std_acc': np.std(acc_scores),\n","                            'f1_macro': np.mean(f1_scores),\n","                            'last_fold_preds': preds_list[-1].tolist(),\n","                            'last_fold_true': y_true_list[-1].tolist()\n","                        })\n","\n","            df = pd.DataFrame(all_results)\n","            df.to_csv(f'classification_results_n{n_points}.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"J17f1LEIMG0n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8fa33b60-55aa-4b7c-b521-ffd4363bb129"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]}],"source":["regression_experiment_run()\n","classification_experiment_run()"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}